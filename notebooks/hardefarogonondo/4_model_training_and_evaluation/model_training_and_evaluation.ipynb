{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20203c0f",
   "metadata": {},
   "source": [
    "# I. Project Team Members"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0aa3d7f4",
   "metadata": {},
   "source": [
    "| Prepared by | Email | Prepared for |\n",
    "| :-: | :-: | :-: |\n",
    "| **_Your Name_** | _Your Email_ | **_Project Name_** |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b05cd469",
   "metadata": {},
   "source": [
    "# II. Notebook Target Definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47bae1d2",
   "metadata": {},
   "source": [
    "_Insert Text Here_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3213f42d",
   "metadata": {},
   "source": [
    "# III. Notebook Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb5c3810",
   "metadata": {},
   "source": [
    "## III.A. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from interpret import set_visualize_provider, show\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret.provider import InlineProvider\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, ConfusionMatrixDisplay, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "set_visualize_provider(InlineProvider())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7291e85b",
   "metadata": {},
   "source": [
    "## III.B. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f425995",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('../../data/processed/X_train_woe.pkl')\n",
    "X_test = pd.read_pickle('../../data/processed/X_test_woe.pkl')\n",
    "y_train = pd.read_pickle('../../data/processed/y_train.pkl')\n",
    "y_test = pd.read_pickle('../../data/processed/y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1433f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f59e32c9",
   "metadata": {},
   "source": [
    "# IV. Models Training and Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db0a5756",
   "metadata": {},
   "source": [
    "## IV.A. Data Shape Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd1fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3389b1bf",
   "metadata": {},
   "source": [
    "## IV.B. Data Information Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe621948",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aef8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce34b86f",
   "metadata": {},
   "source": [
    "## IV.C. Training Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d26f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stamp():\n",
    "    return datetime.now()\n",
    "\n",
    "\n",
    "def create_logger():\n",
    "    return {\n",
    "        \"model_name\": [],\n",
    "        \"model_uid\": [],\n",
    "        \"training_time\": [],\n",
    "        \"training_date\": [],\n",
    "        \"performance\": [],\n",
    "        \"f1_score_avg\": [],\n",
    "        \"data_configurations\": []\n",
    "    }\n",
    "\n",
    "\n",
    "def training_log_updater(current_log, log_path):\n",
    "    try:\n",
    "        with open(log_path, 'r') as file:\n",
    "            last_log = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        with open(log_path, 'w') as file:\n",
    "            file.write(\"[]\")\n",
    "        with open(log_path, 'r') as file:\n",
    "            last_log = json.load(file)\n",
    "    last_log.append(current_log)\n",
    "    with open(log_path, 'w') as file:\n",
    "        json.dump(last_log, file)\n",
    "    return last_log\n",
    "\n",
    "\n",
    "def model_training_and_evaluation(models_list, model_prefix, X_train, y_train, X_test, y_test, data_configuration, log_path):\n",
    "    logger = create_logger()\n",
    "    for model in tqdm(models_list):\n",
    "        model_name = model_prefix + \"-\" + model[\"model_name\"]\n",
    "        start_time = time_stamp()\n",
    "        model[\"model_object\"].fit(X_train, y_train)\n",
    "        finished_time = time_stamp()\n",
    "        elapsed_time = (finished_time - start_time).total_seconds()\n",
    "        y_prediction = model[\"model_object\"].predict(X_test)\n",
    "        performance = classification_report(\n",
    "            y_test, y_prediction, output_dict=True)\n",
    "        original_id = str(start_time) + str(finished_time)\n",
    "        hashed_id = hashlib.md5(original_id.encode()).hexdigest()\n",
    "        model[\"model_uid\"] = hashed_id\n",
    "        logger[\"model_name\"].append(model_name)\n",
    "        logger[\"model_uid\"].append(hashed_id)\n",
    "        logger[\"training_time\"].append(elapsed_time)\n",
    "        logger[\"training_date\"].append(str(start_time))\n",
    "        logger[\"performance\"].append(performance)\n",
    "        logger[\"f1_score_avg\"].append(performance[\"macro avg\"][\"f1-score\"])\n",
    "        logger[\"data_configurations\"].append(data_configuration)\n",
    "    training_log = training_log_updater(logger, log_path)\n",
    "    return training_log, models_list\n",
    "\n",
    "\n",
    "def training_log_to_df_converter(training_log):\n",
    "    all_training_logs_df = pd.DataFrame()\n",
    "    for log in tqdm(training_log):\n",
    "        individual_log_df = pd.DataFrame(log)\n",
    "        performance_df = pd.json_normalize(individual_log_df[\"performance\"])\n",
    "        individual_log_df = pd.concat([individual_log_df.drop(\n",
    "            \"performance\", axis=1), performance_df], axis=1)\n",
    "        all_training_logs_df = pd.concat(\n",
    "            [all_training_logs_df, individual_log_df])\n",
    "    all_training_logs_df.sort_values([\"f1_score_avg\", \"training_time\"], ascending=[\n",
    "                                     False, True], inplace=True)\n",
    "    all_training_logs_df.reset_index(inplace=True, drop=True)\n",
    "    return all_training_logs_df\n",
    "\n",
    "\n",
    "def best_model_finder(all_training_logs_df, models_list):\n",
    "    model_object = None\n",
    "    best_model_info = all_training_logs_df.iloc[0]\n",
    "    for configuration_data in models_list:\n",
    "        for model_data in models_list[configuration_data]:\n",
    "            if model_data[\"model_uid\"] == best_model_info[\"model_uid\"]:\n",
    "                model_object = model_data[\"model_object\"]\n",
    "                break\n",
    "    if model_object == None:\n",
    "        raise RuntimeError(\"The best model not found in your list of model.\")\n",
    "    return model_object"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69eefd12",
   "metadata": {},
   "source": [
    "## IV.D. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68192643",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_baseline = LogisticRegression(random_state=777)\n",
    "ebm_baseline = ExplainableBoostingClassifier(random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9af385",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = {\n",
    "    \"vanilla\": [\n",
    "        {\"model_name\": log_reg_baseline.__class__.__name__,\n",
    "            \"model_object\": log_reg_baseline, \"model_uid\": \"\"},\n",
    "        {\"model_name\": ebm_baseline.__class__.__name__,\n",
    "            \"model_object\": ebm_baseline, \"model_uid\": \"\"}\n",
    "    ],\n",
    "    \"smote\": [\n",
    "        {\"model_name\": log_reg_baseline.__class__.__name__,\n",
    "            \"model_object\": log_reg_baseline, \"model_uid\": \"\"},\n",
    "        {\"model_name\": ebm_baseline.__class__.__name__,\n",
    "            \"model_object\": ebm_baseline, \"model_uid\": \"\"},\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fde862-2df9-475f-a2c6-78bbba00227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a98cf1f",
   "metadata": {},
   "source": [
    "### IV.D.1. Vanilla Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853db323",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log, models_list_vanilla = model_training_and_evaluation(\n",
    "    models_list[\"vanilla\"],\n",
    "    \"baseline_model\",\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    \"vanilla\",\n",
    "    '../../models/logs/training_log.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a23e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03126b44",
   "metadata": {},
   "source": [
    "### IV.D.2. Sampling Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log, models_list_smote = model_training_and_evaluation(\n",
    "    models_list[\"smote\"],\n",
    "    \"smote_model\",\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    \"smote\",\n",
    "    '../../models/logs/training_log.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ac844f9",
   "metadata": {},
   "source": [
    "## IV.E. Models Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d259e2f-1538-4548-9e7f-5f4e9871be78",
   "metadata": {},
   "source": [
    "### IV.E.1. Benchmark Performance Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c0f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance that a model would achieve if it always predicted the most common label.\n",
    "benchmark = y_train.value_counts(normalize=True)[0]\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f14d9-88d7-4ba6-b116-929db1b76c89",
   "metadata": {},
   "source": [
    "### IV.E.2. Baseline Base Model Performance Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2eaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_logs_df = training_log_to_df_converter(training_log)\n",
    "all_training_logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_best_model = best_model_finder(all_training_logs_df, models_list)\n",
    "baseline_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b55c00e-087f-45c8-ac72-0589607b503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_train_prediction = baseline_best_model.predict(X_train)\n",
    "baseline_test_prediction = baseline_best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a571e278-e9c6-4bc0-aa2e-43f6813c1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_train, baseline_train_prediction, ax=ax[0])\n",
    "ax[0].set_title(\"Baseline Train Confusion Matrix\")\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, baseline_test_prediction, ax=ax[1])\n",
    "ax[1].set_title(\"Baseline Test Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c89310-e254-4154-81ed-1cad2166989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_metrics(y_true, y_pred):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "    metrics = {\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1-score\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"auc_roc\": auc_roc\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8a524-d8cc-41f1-8327-743a81b81aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_train_metrics = get_prediction_metrics(\n",
    "    y_train, baseline_train_prediction)\n",
    "baseline_train_metrics[\"dataset\"] = \"Train\"\n",
    "baseline_test_metrics = get_prediction_metrics(\n",
    "    y_test, baseline_test_prediction)\n",
    "baseline_test_metrics[\"dataset\"] = \"Test\"\n",
    "baseline_metrics_df = pd.DataFrame(\n",
    "    [baseline_train_metrics, baseline_test_metrics])\n",
    "baseline_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca534c7e-afba-427f-ac05-4a20fd27d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, baseline_test_prediction)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr,\n",
    "         tpr,\n",
    "         color='darkorange',\n",
    "         lw=2,\n",
    "         label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1],\n",
    "         [0, 1],\n",
    "         color='navy',\n",
    "         lw=2,\n",
    "         linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bb2fc6d",
   "metadata": {},
   "source": [
    "### IV.E.3. Export Baseline Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../models/baseline_best_model.pkl', 'wb') as file:\n",
    "    pickle.dump(baseline_best_model, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de0ed9a4",
   "metadata": {},
   "source": [
    "## IV.F. Hyperparameters Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be189d67",
   "metadata": {},
   "source": [
    "### IV.F.1. Hyperparameters List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7713f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_hyperparams = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [50, 100, 200, 300, 400, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5663b2-0c93-4dfb-b23d-79e98eac1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_grid_search = GridSearchCV(\n",
    "    LogisticRegression(), log_reg_hyperparams, n_jobs=-1, verbose=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30add73-650f-41b2-848a-9f5e56568dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list[\"fine-tuned\"] = [{\"model_name\": log_reg_grid_search.__class__.__name__ + \"-\" +\n",
    "                              log_reg_grid_search.estimator.__class__.__name__, \"model_object\": log_reg_grid_search, \"model_uid\": \"\"}]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7943a5bb",
   "metadata": {},
   "source": [
    "### IV.F.2. Best Model Hyperparameter Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log, models_list_tuned = model_training_and_evaluation(\n",
    "    models_list[\"fine-tuned\"],\n",
    "    \"tuned_model\",\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    \"tuned\",\n",
    "    '../../models/logs/training_log.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c59ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc10a9-fdee-4c0b-951a-5ff793172a27",
   "metadata": {},
   "source": [
    "### IV.E.3. Hyperparameter-tuned Model Performance Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f99ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_logs_df_tuned = training_log_to_df_converter(training_log)\n",
    "all_training_logs_df_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d83b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict_tuned = {\"fine-tuned\": models_list_tuned}\n",
    "tuned_best_model = tuned_model_finder(\n",
    "    models_dict_tuned[\"fine-tuned\"], \"GridSearchCV\")\n",
    "tuned_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf5fc4-c3de-4234-96f1-cb32261a31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_train_prediction = tuned_best_model.predict(X_train)\n",
    "tuned_test_prediction = tuned_best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11ea6d-79f7-4493-8372-a5b2855db8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_train, tuned_train_prediction, ax=ax[0])\n",
    "ax[0].set_title(\"Fine-Tuned Train Confusion Matrix\")\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, tuned_test_prediction, ax=ax[1])\n",
    "ax[1].set_title(\"Fine-Tuned Test Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a770dfd-e4ff-4363-a8af-e73282888419",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_train_metrics = get_prediction_metrics(y_train, tuned_train_prediction)\n",
    "tuned_train_metrics[\"dataset\"] = \"Train\"\n",
    "tuned_test_metrics = get_prediction_metrics(y_test, tuned_test_prediction)\n",
    "tuned_test_metrics[\"dataset\"] = \"Test\"\n",
    "tuned_metrics_df = pd.DataFrame([tuned_train_metrics, tuned_test_metrics])\n",
    "tuned_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e8fa0-5018-4310-b0d1-452d165ccaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, tuned_test_prediction)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr,\n",
    "         tpr,\n",
    "         color='darkorange',\n",
    "         lw=2,\n",
    "         label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1],\n",
    "         [0, 1],\n",
    "         color='navy',\n",
    "         lw=2,\n",
    "         linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44c44a6b",
   "metadata": {},
   "source": [
    "### IV.F.4. Export Hyperparameter-tuned Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../models/tuned_best_model.pkl', 'wb') as file:\n",
    "    pickle.dump(tuned_best_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
